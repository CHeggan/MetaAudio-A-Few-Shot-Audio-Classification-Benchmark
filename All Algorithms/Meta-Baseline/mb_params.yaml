# General params for the problem setting
base:
  # Seed for dataloader and torch model                                                                
  n_way: 5                                                     
  k_shot: 1 
  q_queries: 1
  # Distance to use for matching samples                                                            
  distance: 'cosine'                                                                
  task_type: 'MB_5s_joint_lr_VoxCeleb_SHIFTED_'
  num_repeats: 1
  cuda: 0

models: ['Hybrid']

mb_specific:
  scaling_factor: 10.0
  learnable: True

hyper:
  meta_lr: 0.001 #0.0001
  # The lowest lr that is ever hit                                                             
  min_lr: 0.0001
  # Patience for val loss
  patience: 100000
  # Factor of lr reduction-new_lr = lr*factor
  factor: 0.1           
  # Number of epochs to warm up for before using scheduler
  scheduler_warm_up: 10                                                                

training:
  epochs: 5000
  episodes_per_epoch: 10
  train_batch_size: 10 # 50

  # How many tasks we want at each step
  val_tasks: 200
  test_tasks: 10000

  # Episodes between validation steps
  eval_spacing: 100                                                 
  trans_batch: False

  # Number workers for the dataloaders
  num_workers: 4                                                                  

data:
  variable: True
  name: 'VoxCeleb_5s' # Kaggle_18
  norm: 'global'
  type: 'variable_spec' #/spec/variable_spec
  fixed: True
  fixed_path: 'dataset_/splits/VoxCeleb_shifted_split.npy'

  data_path: 'X:/Datasets/VoxCeleb1/VoxSpec_5_seconds'


# Split percentages for train/val/test
split:
  train: 0.7
  val: 0.1
  test: 0.2
